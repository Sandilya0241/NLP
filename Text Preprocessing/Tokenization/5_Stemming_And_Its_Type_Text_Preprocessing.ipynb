{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b56f3e2",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes or to the roots of words known as Lemma. Stemming is important in natural language understanding (NLU) and natual language processing (NLP).\n",
    "\n",
    "Let us say we have a Classification problem:\n",
    "\n",
    "Comments of product is a positive review or negative review.\n",
    "\n",
    "Review --> \n",
    "\n",
    "Eating, Eat, Eaten (Stem word : Eat)\n",
    "\n",
    "Goes, Going, Gone (Stem word : Go)\n",
    "\n",
    "We are reducing the input vectors by doing this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "078d21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\",\"eats\", \"eaten\", \"writing\", \"writes\", \"programming\", \"programs\",\"history\",\"finally\", \"finalized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e7419c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating --> eat\n",
      "eats --> eat\n",
      "eaten --> eaten\n",
      "writing --> write\n",
      "writes --> write\n",
      "programming --> program\n",
      "programs --> program\n",
      "history --> histori\n",
      "finally --> final\n",
      "finalized --> final\n"
     ]
    }
   ],
   "source": [
    "# Porter Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "for word in words:\n",
    "    print(f\"{word} --> {ps.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20276c44",
   "metadata": {},
   "source": [
    "If we see above, eaten changed to eaten and History changed to Histori. Eaten is fine but with Historia complete meaning is changed. This is the major disadvantage of Stemming. Let us see one more example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8af8c999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"Congratulations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7bc75c",
   "metadata": {},
   "source": [
    "#### Regexstemmer Class\n",
    "\n",
    "NLTK has Regexstemmer class with the help of which we can easily implement Regular Expression Stemmer algorithm. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4d1f045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingeat\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "regxStemmer = RegexpStemmer('ing$|s$|ed$')\n",
    "print(regxStemmer.stem(\"ingeating\"))\n",
    "\n",
    "regxStemmer = RegexpStemmer('ing|s$|ed$')\n",
    "print(regxStemmer.stem(\"ingeating\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7eb1e2",
   "metadata": {},
   "source": [
    "### Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c758cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating --> eat\n",
      "eats --> eat\n",
      "eaten --> eaten\n",
      "writing --> write\n",
      "writes --> write\n",
      "programming --> program\n",
      "programs --> program\n",
      "history --> histori\n",
      "finally --> final\n",
      "finalized --> final\n"
     ]
    }
   ],
   "source": [
    "# %pip install scikit-learn\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "ss = SnowballStemmer(language='english')\n",
    "for word in words:\n",
    "    print(f\"{word} --> {ss.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b29abbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairli\n",
      "sportingli\n",
      "goe\n",
      "----\n",
      "fair\n",
      "sport\n",
      "goe\n"
     ]
    }
   ],
   "source": [
    "### Compare PorterStemmer and SnowballStemmer\n",
    "ps = PorterStemmer()\n",
    "print(ps.stem(\"fairly\"))\n",
    "print(ps.stem(\"sportingly\"))\n",
    "print(ps.stem(\"goes\"))\n",
    "print(\"----\")\n",
    "ss = SnowballStemmer(language='english')\n",
    "print(ss.stem(\"fairly\"))\n",
    "print(ss.stem(\"sportingly\"))\n",
    "print(ss.stem(\"goes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548270e2",
   "metadata": {},
   "source": [
    "How much ever we try, there are some words which are not stemmed accurately.\n",
    "\n",
    "For chatbot kind of applications, we cannot use this Stemming technique.\n",
    "\n",
    "We can go with Lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1691c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b633b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed3f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805bcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ba244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433284d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbdf9a3d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
