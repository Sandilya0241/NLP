{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df95f9dd",
   "metadata": {},
   "source": [
    "# Conditional GAN (cGAN) - Cats vs Dogs Image Generation\n",
    "## Project Overview\n",
    "This notebook implements a Conditional Generative Adversarial Network (cGAN) to generate images of cats or dogs conditioned on class labels.\n",
    "\n",
    "- **Label 0**: Cat\n",
    "- **Label 1**: Dog\n",
    "\n",
    "The model learns to generate realistic cat and dog images based on the specified label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a91f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 64\n",
    "NOISE_DIM = 100\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0002\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b3f9b",
   "metadata": {},
   "source": [
    "## Part 1: Load and Prepare Cats vs Dogs Dataset\n",
    "\n",
    "We will load the Cats vs Dogs dataset using `tensorflow_datasets` with split information enabled.\n",
    "The dataset contains over 23,000 labeled images:\n",
    "- Label 0 = Cat\n",
    "- Label 1 = Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Cats vs Dogs dataset with info\n",
    "print(\"Loading Cats vs Dogs dataset...\")\n",
    "(train_images, train_labels), (test_images, test_labels), info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset info:\\n{info}\")\n",
    "print(f\"\\nTraining samples: {len(list(train_images))}\")\n",
    "print(f\"Testing samples: {len(list(test_images))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213edb83",
   "metadata": {},
   "source": [
    "## Part 2: Preprocess Images and Labels\n",
    "\n",
    "We will:\n",
    "1. Resize all images to 64×64 pixels\n",
    "2. Normalize pixel values to [-1, 1] range\n",
    "3. Cast labels to integer format\n",
    "4. Create training batches with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    \"\"\"\n",
    "    Preprocess image and label:\n",
    "    - Resize image to IMG_SIZE x IMG_SIZE\n",
    "    - Normalize pixel values to [-1, 1] range\n",
    "    - Cast label to int32\n",
    "    \"\"\"\n",
    "    # Convert image to float32\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    # Resize to 64x64\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    \n",
    "    # Normalize to [-1, 1] range (from [0, 1])\n",
    "    image = (image * 2.0) - 1.0\n",
    "    \n",
    "    # Cast label to int32\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing and batching to training dataset\n",
    "train_dataset = train_images.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.cache().shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Apply preprocessing and batching to test dataset\n",
    "test_dataset = test_images.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"Training dataset: {train_dataset}\")\n",
    "print(f\"Test dataset: {test_dataset}\")\n",
    "\n",
    "# Visualize a few preprocessed samples\n",
    "sample_images, sample_labels = next(iter(train_dataset.take(1)))\n",
    "print(f\"\\nSample batch shape: {sample_images.shape}\")\n",
    "print(f\"Sample labels: {sample_labels.numpy()}\")\n",
    "print(f\"Image value range: [{sample_images.numpy().min():.2f}, {sample_images.numpy().max():.2f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac9de0",
   "metadata": {},
   "source": [
    "## Part 3: Build Generator Network\n",
    "\n",
    "The generator:\n",
    "- Takes a noise vector and class label as input\n",
    "- Embeds the label and concatenates with noise\n",
    "- Uses Conv2DTranspose layers to upsample to 64×64×3 image\n",
    "- Outputs image with tanh activation (values in [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e692461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \"\"\"\n",
    "    Build the generator network that takes noise and class label and generates 64x64x3 images.\n",
    "    \"\"\"\n",
    "    # Inputs\n",
    "    noise_input = tf.keras.layers.Input(shape=(NOISE_DIM,), name='noise')\n",
    "    label_input = tf.keras.layers.Input(shape=(), dtype='int32', name='label')\n",
    "    \n",
    "    # Label embedding: Convert label to embedding vector\n",
    "    label_emb = tf.keras.layers.Embedding(NUM_CLASSES, 50)(label_input)\n",
    "    label_emb = tf.keras.layers.Flatten()(label_emb)\n",
    "    \n",
    "    # Concatenate noise and label embedding\n",
    "    x = tf.keras.layers.Concatenate()([noise_input, label_emb])\n",
    "    \n",
    "    # Dense layer to project to initial spatial dimensions (8x8x256)\n",
    "    x = tf.keras.layers.Dense(8 * 8 * 256, use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    # Reshape to 8x8x256\n",
    "    x = tf.keras.layers.Reshape((8, 8, 256))(x)\n",
    "    \n",
    "    # Conv2DTranspose layer 1: 8x8 -> 16x16\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    # Conv2DTranspose layer 2: 16x16 -> 32x32\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    # Conv2DTranspose layer 3: 32x32 -> 64x64\n",
    "    x = tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='tanh')(x)\n",
    "    \n",
    "    # Create model\n",
    "    generator = tf.keras.Model([noise_input, label_input], x, name='generator')\n",
    "    return generator\n",
    "\n",
    "# Build generator\n",
    "generator = build_generator()\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c8480",
   "metadata": {},
   "source": [
    "## Part 4: Build Discriminator Network\n",
    "\n",
    "The discriminator:\n",
    "- Takes a 64×64×3 image and class label as input\n",
    "- Embeds the label and concatenates with image\n",
    "- Uses Conv2D layers to downsampl and classify\n",
    "- Outputs a single value (real=1, fake=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Build the discriminator network that takes 64x64x3 images and class labels\n",
    "    and outputs a single value indicating real or fake.\n",
    "    \"\"\"\n",
    "    # Inputs\n",
    "    image_input = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='image')\n",
    "    label_input = tf.keras.layers.Input(shape=(), dtype='int32', name='label')\n",
    "    \n",
    "    # Label embedding: Convert label to spatial map\n",
    "    label_emb = tf.keras.layers.Embedding(NUM_CLASSES, 50)(label_input)\n",
    "    label_emb = tf.keras.layers.Flatten()(label_emb)\n",
    "    \n",
    "    # Expand label to spatial dimensions and concatenate with image\n",
    "    label_map = tf.keras.layers.Dense(IMG_SIZE * IMG_SIZE * 1)(label_emb)\n",
    "    label_map = tf.keras.layers.Reshape((IMG_SIZE, IMG_SIZE, 1))(label_map)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([image_input, label_map])\n",
    "    \n",
    "    # Conv2D layer 1: 64x64 -> 32x32\n",
    "    x = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Conv2D layer 2: 32x32 -> 16x16\n",
    "    x = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Conv2D layer 3: 16x16 -> 8x8\n",
    "    x = tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Flatten and output\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    # Create model\n",
    "    discriminator = tf.keras.Model([image_input, label_input], x, name='discriminator')\n",
    "    return discriminator\n",
    "\n",
    "# Build discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225f08b",
   "metadata": {},
   "source": [
    "## Part 5: Define Loss Functions and Optimizers\n",
    "\n",
    "We use:\n",
    "- **Binary Cross-Entropy Loss**: For both generator and discriminator\n",
    "- **Generator Loss**: Encourages discriminator to classify generated images as real\n",
    "- **Discriminator Loss**: Distinguishes between real and fake images\n",
    "- **Adam Optimizer**: For both networks with learning rate 0.0002 and beta_1=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b8647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "cross_entropy_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    \"\"\"\n",
    "    Generator loss: We want the discriminator to classify generated images as real (label=1).\n",
    "    \"\"\"\n",
    "    return cross_entropy_loss(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"\n",
    "    Discriminator loss: Distinguish between real (label=1) and fake (label=0) images.\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy_loss(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy_loss(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "# Define optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=0.5)\n",
    "\n",
    "print(\"Loss functions and optimizers defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2bae74",
   "metadata": {},
   "source": [
    "## Part 6: Create Training Loop\n",
    "\n",
    "The training process:\n",
    "1. For each batch: Generate fake images from noise and labels\n",
    "2. Discriminator: Classify real and fake images\n",
    "3. Compute losses and apply gradients alternately\n",
    "4. Use @tf.function for optimization\n",
    "5. Train for 10+ epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store losses for visualization\n",
    "train_gen_losses = []\n",
    "train_disc_losses = []\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    \"\"\"\n",
    "    Single training step: Update generator and discriminator alternately.\n",
    "    \n",
    "    Args:\n",
    "        images: Batch of real images\n",
    "        labels: Batch of labels\n",
    "        \n",
    "    Returns:\n",
    "        Generator loss and discriminator loss\n",
    "    \"\"\"\n",
    "    # Generate random noise for generator input\n",
    "    noise = tf.random.normal([tf.shape(images)[0], NOISE_DIM])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generate fake images\n",
    "        generated_images = generator([noise, labels], training=True)\n",
    "        \n",
    "        # Discriminator predictions\n",
    "        real_output = discriminator([images, labels], training=True)\n",
    "        fake_output = discriminator([generated_images, labels], training=True)\n",
    "        \n",
    "        # Calculate losses\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    # Apply gradients\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_gen_loss = 0.0\n",
    "    epoch_disc_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for images, labels in train_dataset:\n",
    "        gen_loss, disc_loss = train_step(images, labels)\n",
    "        epoch_gen_loss += gen_loss\n",
    "        epoch_disc_loss += disc_loss\n",
    "        num_batches += 1\n",
    "    \n",
    "    # Calculate average losses for the epoch\n",
    "    avg_gen_loss = epoch_gen_loss / num_batches\n",
    "    avg_disc_loss = epoch_disc_loss / num_batches\n",
    "    \n",
    "    train_gen_losses.append(avg_gen_loss)\n",
    "    train_disc_losses.append(avg_disc_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Gen Loss: {avg_gen_loss:.4f}, Disc Loss: {avg_disc_loss:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_gen_losses, label='Generator Loss')\n",
    "plt.plot(train_disc_losses, label='Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d907d6a",
   "metadata": {},
   "source": [
    "## Part 7: Generate and Visualize Conditional Images\n",
    "\n",
    "Generate images conditioned on class labels and display with titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_display_images(num_examples_per_class=4):\n",
    "    \"\"\"\n",
    "    Generate images conditioned on labels and display with titles.\n",
    "    \n",
    "    Args:\n",
    "        num_examples_per_class: Number of images to generate for each class\n",
    "    \"\"\"\n",
    "    # Label names\n",
    "    label_names = {0: 'Cat', 1: 'Dog'}\n",
    "    \n",
    "    # Create figure for generated images\n",
    "    fig, axes = plt.subplots(2, num_examples_per_class, figsize=(15, 6))\n",
    "    fig.suptitle('Generated Images Conditioned on Class Labels', fontsize=16)\n",
    "    \n",
    "    for class_label in range(NUM_CLASSES):\n",
    "        # Generate random noise\n",
    "        noise = tf.random.normal([num_examples_per_class, NOISE_DIM])\n",
    "        \n",
    "        # Create labels array\n",
    "        labels = np.full((num_examples_per_class,), class_label, dtype=np.int32)\n",
    "        \n",
    "        # Generate images\n",
    "        generated_images = generator([noise, labels], training=False)\n",
    "        \n",
    "        # Normalize images from [-1, 1] to [0, 1] for display\n",
    "        generated_images = (generated_images + 1.0) / 2.0\n",
    "        \n",
    "        # Display images\n",
    "        for i in range(num_examples_per_class):\n",
    "            ax = axes[class_label, i]\n",
    "            ax.imshow(generated_images[i].numpy())\n",
    "            ax.set_title(f'{label_names[class_label]}')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and display conditional images\n",
    "generate_and_display_images(num_examples_per_class=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualization: Generate more samples and create a larger grid\n",
    "def generate_large_sample_grid(num_per_class=8):\n",
    "    \"\"\"Generate a larger grid of images for visual evaluation.\"\"\"\n",
    "    label_names = {0: 'Cat', 1: 'Dog'}\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    fig.suptitle('cGAN Generated Image Grid - Label-Conditioned Samples', fontsize=16)\n",
    "    \n",
    "    image_count = 1\n",
    "    for class_label in range(NUM_CLASSES):\n",
    "        # Generate noise and labels\n",
    "        noise = tf.random.normal([num_per_class, NOISE_DIM])\n",
    "        labels = np.full((num_per_class,), class_label, dtype=np.int32)\n",
    "        \n",
    "        # Generate images\n",
    "        generated_images = generator([noise, labels], training=False)\n",
    "        generated_images = (generated_images + 1.0) / 2.0  # Normalize to [0, 1]\n",
    "        \n",
    "        # Display in grid\n",
    "        for i in range(num_per_class):\n",
    "            ax = plt.subplot(2, num_per_class, image_count)\n",
    "            ax.imshow(generated_images[i].numpy())\n",
    "            ax.set_title(f'{label_names[class_label]} #{i+1}', fontsize=10)\n",
    "            ax.axis('off')\n",
    "            image_count += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate large sample grid\n",
    "generate_large_sample_grid(num_per_class=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fe8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the cGAN Model\n",
    "print(\"=\" * 60)\n",
    "print(\"CONDITIONAL GAN (cGAN) - TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Epochs Trained: {EPOCHS}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Noise Dimension: {NOISE_DIM}\")\n",
    "print(f\"Image Size: {IMG_SIZE} x {IMG_SIZE}\")\n",
    "print(f\"Number of Classes: {NUM_CLASSES}\")\n",
    "print(f\"\\nFinal Generator Loss: {train_gen_losses[-1]:.4f}\")\n",
    "print(f\"Final Discriminator Loss: {train_disc_losses[-1]:.4f}\")\n",
    "print(\"\\nModel Architectures:\")\n",
    "print(\"- Generator: Accepts noise + label → Generates 64x64x3 images\")\n",
    "print(\"- Discriminator: Accepts image + label → Outputs real/fake prediction\")\n",
    "print(\"\\nKey Features:\")\n",
    "print(\"- Label embedding and concatenation\")\n",
    "print(\"- Batch normalization for stable training\")\n",
    "print(\"- LeakyReLU activation functions\")\n",
    "print(\"- Binary cross-entropy loss\")\n",
    "print(\"- Adam optimizer with lr=0.0002, beta_1=0.5\")\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
